{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a12c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n",
      "\n",
      "download mnist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 13:47:58.774845: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Failed precondition: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /Users/karanjogi/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5ec7be8e874958a6874682e000df52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to /Users/karanjogi/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "create and compile model\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 13:48:05.808596: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-24 13:48:05.808728: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-03-24 13:48:06.399951: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-03-24 13:48:06.402514: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-03-24 13:48:06.403075: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937/938 [============================>.] - ETA: 0s - loss: 0.1876 - accuracy: 0.9411"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 13:48:19.137289: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 14s 11ms/step - loss: 0.1875 - accuracy: 0.9411 - val_loss: 0.0537 - val_accuracy: 0.9820\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0503 - accuracy: 0.9845 - val_loss: 0.0397 - val_accuracy: 0.9859\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0339 - accuracy: 0.9893 - val_loss: 0.0252 - val_accuracy: 0.9916\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0257 - accuracy: 0.9918 - val_loss: 0.0266 - val_accuracy: 0.9918\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0208 - accuracy: 0.9938 - val_loss: 0.0251 - val_accuracy: 0.9922\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.0312 - val_accuracy: 0.9908\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.0271 - val_accuracy: 0.9916\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.0277 - val_accuracy: 0.9920\n",
      "Epoch 9/100\n",
      "855/938 [==========================>...] - ETA: 0s - loss: 0.0106 - accuracy: 0.9968"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# load MNIST\n",
    "print('\\ndownload mnist')\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.batch(BATCH_SIZE)\n",
    "\n",
    "print('\\ncreate and compile model')\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(ds_train, epochs=EPOCHS, validation_data=ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae5eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
